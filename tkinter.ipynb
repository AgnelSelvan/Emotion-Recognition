{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from setuptools import setup\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 images belonging to 6 classes.\n",
      "{0: 'Angry', 1: 'Fear', 2: 'Happy', 3: 'Neutral', 4: 'Sad', 5: 'Surprise'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\agnelselvan\\appdata\\local\\programs\\python\\python37\\lib\\tkinter\\__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-4-39dd62a1b845>\", line 190, in detectEmotion\n",
      "    recognizer.read('./PersonalFace/trained model/trainner.yml')\n",
      "cv2.error: OpenCV(4.0.0) C:\\projects\\opencv-python\\opencv_contrib\\modules\\face\\src\\facerec.cpp:61: error: (-2:Unspecified error) File can't be opened for reading! in function 'cv::face::FaceRecognizer::read'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./HaarCascade/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def faceRecord():\n",
    "    \n",
    "    cap = cv2.VideoCapture(1)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('./PersonalFace/out.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        out.write(frame)\n",
    "        cv2.imshow(\"image\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    cap = cv2.VideoCapture('./PersonalFace/sample.mp4')\n",
    "    \n",
    "\n",
    "    currentFrame = 0\n",
    "    name = input(\"Enter Your Name: \")\n",
    "    dirs = './PersonalFace/images/'+str(name)\n",
    "    # print(dir)\n",
    "    if os.path.exists(dirs):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(dirs)\n",
    "    if name:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            dirs = './PersonalFace/images/'+str(name)+'/'+str(currentFrame)+'.jpg'\n",
    "            cv2.imwrite(dirs, frame)\n",
    "\n",
    "            currentFrame += 1\n",
    "            if cv2.waitKey(1) == 13:\n",
    "                break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def trainFace():\n",
    "\n",
    "    \n",
    "    \n",
    "    BASE_DIR = os.path.dirname(os.path.abspath('__file__'))\n",
    "    BASE_DIR = BASE_DIR+'/PersonalFace'\n",
    "    print(BASE_DIR)\n",
    "    img_dir = os.path.join(BASE_DIR, \"images\")\n",
    "    print(img_dir)\n",
    "\n",
    "    ##Loading images and cropping the image\n",
    "    i = 0\n",
    "    for root, dirs, files in os.walk(img_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "                path = os.path.join(root, file)\n",
    "                img = cv2.imread(path)\n",
    "                img = cv2.resize(img, (280, 280))\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "                for (x, y, w, h) in faces:\n",
    "                        img_name = str(root)+\"/\"+str(i)+\".jpg\"\n",
    "                        print(img_name)\n",
    "                        roi_color = img[y:y+h+20, x:x+w+20]\n",
    "                        cv2.imwrite(img_name, roi_color)\n",
    "                        #cv2.imshow(\"Frame\",roi_color)\n",
    "                        i += 1\n",
    "                cv2.waitKey(0)\n",
    "    \n",
    "    current_ids = 0\n",
    "    label_ids = {}\n",
    "    x_train = []\n",
    "    y_labels = []\n",
    "    for root, dirs, files in os.walk(img_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "                path = os.path.join(root, file)\n",
    "                label = os.path.basename(root).replace(' ', \"-\")\n",
    "                if label in label_ids:\n",
    "                    pass\n",
    "                else:\n",
    "                    label_ids[label] = current_ids\n",
    "                    current_ids += 1\n",
    "                id_ = label_ids[label]\n",
    "                #print(label_ids)\n",
    "                pil_image = Image.open(path).convert(\"L\")\n",
    "                image_array = np.array(pil_image, 'uint8')\n",
    "                #print(image_array)\n",
    "                faces = face_cascade.detectMultiScale(image_array, 1.5, 5)\n",
    "\n",
    "                for(x, y, w, h) in faces:\n",
    "                    roi = image_array[y:y+h, x:x+w]\n",
    "                    x_train.append(roi)\n",
    "                    y_labels.append(id_)\n",
    "\n",
    "    # print(x_train)\n",
    "    # print(y_labels)\n",
    "\n",
    "    #############Saving the model and label using pickle ##############\n",
    "\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "    with open(\"./PersonalFace/trained model/label.pickle\", \"wb\") as f:\n",
    "        pickle.dump(label_ids, f)\n",
    "\n",
    "    recognizer.train(x_train, np.array(y_labels))\n",
    "    recognizer.save(\"./PersonalFace/trained model/trainner.yml\")\n",
    "\n",
    "def personalFace():\n",
    "    eye_cascade = cv2.CascadeClassifier('./HaarCascade/haarcascade_eye.xml')\n",
    "    smile_cascade = cv2.CascadeClassifier('./HaarCascade/haarcascade_smile.xml')\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.read(\"./PersonalFace/trained model/trainner.yml\")\n",
    "\n",
    "    labels = {}\n",
    "    with open('./PersonalFace/trained model/label.pickle', 'rb') as f:\n",
    "        og_labels = pickle.load(f)\n",
    "        labels = {v:k for k, v in og_labels.items()}\n",
    "\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    i = 0\n",
    "    stroke = 2\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            #print(x, y, w, h)\n",
    "            img_item = str(i)+\".png\"\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "            id_, conf = recognizer.predict(roi_gray)\n",
    "            #print(labels[id_])\n",
    "            cv2.putText(frame, labels[id_], (x, y), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), stroke)\n",
    "\n",
    "            color= (0, 0, 255) #BGR\n",
    "            stroke = 2\n",
    "            width = x + w\n",
    "            height = y + h\n",
    "            cv2.rectangle(frame, (x - 10, y), (width + 10, height + 20), color, stroke)\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "            #for (ex, ey, ew, eh) in eyes:\n",
    "            #   cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0))\n",
    "            # smile = smile_cascade.detectMultiScale(roi_gray)\n",
    "            # for (sx, sy, sw, sh) in smile:\n",
    "            #     cv2.rectangle(roi_color, (sx, sy), (sx+sw, sy+sh), (255, 0, 0))\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def detectEmotion():\n",
    "    num_classes = 6\n",
    "    img_rows, img_cols = 48, 48\n",
    "    batch_size = 16\n",
    "\n",
    "    train_data_dir = './images/train'\n",
    "    validation_data_dir = './images/validation'\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        color_mode='grayscale',\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False    \n",
    "    )\n",
    "\n",
    "    class_labels = validation_generator.class_indices\n",
    "    class_labels = {v: k for k, v in class_labels.items()}\n",
    "    classes = list(class_labels.values())\n",
    "    print(class_labels)\n",
    "    \n",
    "    classifier = load_model('./TrainedModel/4(67)/Emotion_detector.h5')    \n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.read('./PersonalFace/trained model/trainner.yml')\n",
    "\n",
    "    labels = {}\n",
    "    with open('./PersonalFace/trained model/label.pickle', 'rb') as f:\n",
    "        og_label = pickle.load(f)\n",
    "        labels = {v: k for k, v in og_label.items()}\n",
    "    # print(labels)\n",
    "\n",
    "    def face_detector(img, gray):\n",
    "        #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        if faces == ():\n",
    "            return (0, 0, 0, 0), np.zeros((48, 48), np.uint8), img\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(img, (x-30, y-30), (x+w+20, y+h+20), (255, 0, 0), 2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "        try:\n",
    "            roi_gray = cv2.resize(roi_gray, (48, 48), interpolation=cv2.INTER_AREA)\n",
    "        except:\n",
    "            return (x, y, w, h), np.zeros((48, 48), np.uint8), img\n",
    "\n",
    "        return (x, y, w, h), roi_gray, img\n",
    "\n",
    "    cap = cv2.VideoCapture(1)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rect, face, image = face_detector(frame, gray)\n",
    "        if np.sum([face]) != 0.0:\n",
    "            roi = face.astype(\"float\") / 255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi, axis=0)\n",
    "            preds = classifier.predict(roi)[0]\n",
    "\n",
    "            roi_gray = gray[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]]\n",
    "            id_, conf = recognizer.predict(roi_gray)\n",
    "\n",
    "            label = labels[id_]+\" is \"+class_labels[preds.argmax()]\n",
    "            label_position = (rect[0] + int((rect[1]/2)), rect[2] + 25)\n",
    "            cv2.putText(image, label, label_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        else:\n",
    "            cv2.putText(image, \"No Face found\", (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 1)\n",
    "\n",
    "        cv2.imshow('Emotion Detection', image)\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "root.title(\"Personal Face Recognition and Emotion-Recognition\")\n",
    "root.geometry('500x570')\n",
    "tf = Frame(root, width = 480, height = 50, bd = 2, relief = \"ridge\")\n",
    "tf.place(x = 10, y = 10)\n",
    "title = Label(tf,font = (\"Helvetica\",30),fg = \"blue\",text = \"       Emotion Detection      \")\n",
    "title.pack() \n",
    "\n",
    "button1 = Button(root, command = faceRecord, padx = 5, pady = 5, relief = RIDGE, width = 33, background = 'cyan',font  = (\"georgia\",15), text = \"Open webcam for personal face detection\", bd = 5)\n",
    "button1.place(x = 20, y = 80)\n",
    "\n",
    "button2 = Button(root, command = trainFace, padx = 5, pady = 5, relief = RIDGE, width = 33, background = 'cyan',font  = (\"georgia\",15), text = \"Train your face\", bd = 5)\n",
    "button2.place(x = 20, y = 160)\n",
    "\n",
    "button3 = Button(root, command = personalFace, padx = 5, pady = 5, relief = RIDGE, width = 33, background = 'cyan',font  = (\"georgia\",15), text = \"Your Personal Face\", bd = 5)\n",
    "button3.place(x = 20, y = 240)\n",
    "\n",
    "button4 = Button(root, command = detectEmotion, padx = 5, pady = 5, relief = RIDGE, width = 33, background = 'cyan',font  = (\"georgia\",15), text = \"Emotion with your face\", bd = 5)\n",
    "button4.place(x = 20, y = 320)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 216 images belonging to 6 classes.\n",
      "{0: 'Angry', 1: 'Fear', 2: 'Happy', 3: 'Neutral', 4: 'Sad', 5: 'Surprise'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\agnelselvan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:201: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5577046\n",
      "0.65334594\n",
      "0.61936015\n",
      "0.7244444\n",
      "0.74880946\n",
      "0.76279324\n",
      "0.75207436\n",
      "0.7320087\n",
      "0.70742553\n",
      "0.7476492\n",
      "0.6707093\n",
      "0.6935068\n",
      "0.729263\n",
      "0.7568801\n",
      "0.77066207\n",
      "0.8159195\n",
      "0.7872267\n",
      "0.8229791\n",
      "0.8404441\n",
      "0.84000474\n",
      "0.83831286\n",
      "0.8490247\n",
      "0.83142906\n",
      "0.860814\n",
      "0.83009404\n",
      "0.83428395\n",
      "0.8209153\n",
      "0.7911509\n",
      "0.84380233\n",
      "0.8277989\n",
      "0.8380528\n",
      "0.8231383\n",
      "0.7927022\n",
      "0.7826618\n",
      "0.7738114\n",
      "0.5247597\n",
      "0.47001016\n",
      "0.57354707\n",
      "0.59600204\n",
      "0.7316989\n",
      "0.61460847\n",
      "0.7408464\n",
      "0.72058976\n",
      "0.68837184\n",
      "0.7852026\n",
      "0.79681426\n",
      "0.75486624\n",
      "0.7463243\n",
      "0.78322446\n",
      "0.79323024\n",
      "0.7475324\n",
      "0.75307393\n",
      "0.7648914\n",
      "0.7631644\n",
      "0.7791217\n",
      "0.76134396\n",
      "0.84541494\n",
      "0.83680385\n",
      "0.6931305\n",
      "0.7594037\n",
      "0.7522116\n",
      "0.6878047\n",
      "0.6606973\n",
      "0.7373388\n",
      "0.7823187\n",
      "0.8254546\n",
      "0.8076195\n",
      "0.7644389\n",
      "0.8374533\n",
      "0.8338466\n",
      "0.8700759\n",
      "0.9006712\n",
      "0.89085746\n",
      "0.90314454\n",
      "0.859679\n",
      "0.8666711\n",
      "0.8794533\n",
      "0.8856491\n",
      "0.89387363\n",
      "0.88238144\n",
      "0.8912891\n",
      "0.84985805\n",
      "0.85457176\n",
      "0.8546544\n",
      "0.8651765\n",
      "0.84230936\n",
      "0.8475945\n",
      "0.8314406\n",
      "0.8470923\n",
      "0.87255865\n",
      "0.8384464\n",
      "0.8942609\n",
      "0.8412971\n",
      "0.82918686\n",
      "0.8611083\n",
      "0.8469281\n",
      "0.87778383\n",
      "0.862492\n",
      "0.8869529\n",
      "0.8286701\n",
      "0.7885331\n",
      "0.7607816\n",
      "0.9026139\n",
      "0.8528313\n",
      "0.7473537\n",
      "0.7373514\n",
      "0.79492533\n",
      "0.81138307\n",
      "0.8114376\n",
      "0.8109548\n",
      "0.74959713\n",
      "0.76036054\n",
      "0.74728936\n",
      "0.6962984\n",
      "0.7996753\n",
      "0.3511487\n",
      "0.53417796\n",
      "0.5183077\n",
      "0.4656966\n",
      "0.37743658\n",
      "0.40412664\n",
      "0.53300065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\agnelselvan\\appdata\\local\\programs\\python\\python37\\lib\\tkinter\\__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-4-cd133beb0fb4>\", line 222, in detectEmotion\n",
      "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
      "cv2.error: OpenCV(4.0.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./HaarCascade/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def faceRecord():\n",
    "    \n",
    "    cap = cv2.VideoCapture(1)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('./PersonalFace/out.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        out.write(frame)\n",
    "        cv2.imshow(\"image\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    cap = cv2.VideoCapture('./PersonalFace/sample.mp4')\n",
    "    \n",
    "\n",
    "    currentFrame = 0\n",
    "    name = input(\"Enter Your Name: \")\n",
    "    dirs = './PersonalFace/images/'+str(name)\n",
    "    # print(dir)\n",
    "    if os.path.exists(dirs):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(dirs)\n",
    "    if name:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            dirs = './PersonalFace/images/'+str(name)+'/'+str(currentFrame)+'.jpg'\n",
    "            \n",
    "            image = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE) \n",
    "            cv2.imwrite(dirs, image)\n",
    "\n",
    "            currentFrame += 1\n",
    "            if cv2.waitKey(1) == 13:\n",
    "                break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def trainFace():\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath('__file__'))\n",
    "    BASE_DIR = BASE_DIR+'/PersonalFace'\n",
    "    print(BASE_DIR)\n",
    "    img_dir = os.path.join(BASE_DIR, \"images\")\n",
    "    print(img_dir)\n",
    "\n",
    "    ##Loading images and cropping the image\n",
    "    i = 0\n",
    "    for root, dirs, files in os.walk(img_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "                path = os.path.join(root, file)\n",
    "                img = cv2.imread(path)\n",
    "                img = cv2.resize(img, (280, 280))\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "                for (x, y, w, h) in faces:\n",
    "                        img_name = str(root)+\"/\"+str(i)+\".jpg\"\n",
    "                        print(img_name)\n",
    "                        roi_color = img[y:y+h+20, x:x+w+20]\n",
    "                        cv2.imwrite(img_name, roi_color)\n",
    "                        #cv2.imshow(\"Frame\",roi_color)\n",
    "                        i += 1\n",
    "                cv2.waitKey(0)\n",
    "    \n",
    "    current_ids = 0\n",
    "    label_ids = {}\n",
    "    x_train = []\n",
    "    y_labels = []\n",
    "    for root, dirs, files in os.walk(img_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "                path = os.path.join(root, file)\n",
    "                label = os.path.basename(root).replace(' ', \"-\")\n",
    "                if label in label_ids:\n",
    "                    pass\n",
    "                else:\n",
    "                    label_ids[label] = current_ids\n",
    "                    current_ids += 1\n",
    "                id_ = label_ids[label]\n",
    "                #print(label_ids)\n",
    "                pil_image = Image.open(path).convert(\"L\")\n",
    "                image_array = np.array(pil_image, 'uint8')\n",
    "                #print(image_array)\n",
    "                faces = face_cascade.detectMultiScale(image_array, 1.5, 5)\n",
    "\n",
    "                for(x, y, w, h) in faces:\n",
    "                    roi = image_array[y:y+h, x:x+w]\n",
    "                    x_train.append(roi)\n",
    "                    y_labels.append(id_)\n",
    "\n",
    "    # print(x_train)\n",
    "    # print(y_labels)\n",
    "\n",
    "    #############Saving the model and label using pickle ##############\n",
    "\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "    with open(\"./PersonalFace/trainedmodel/label.pickle\", \"wb\") as f:\n",
    "        pickle.dump(label_ids, f)\n",
    "\n",
    "    recognizer.train(x_train, np.array(y_labels))\n",
    "    recognizer.save(\"./PersonalFace/trainedmodel/trainner.yml\")\n",
    "\n",
    "def personalFace():\n",
    "    eye_cascade = cv2.CascadeClassifier('./HaarCascade/haarcascade_eye.xml')\n",
    "    smile_cascade = cv2.CascadeClassifier('./HaarCascade/haarcascade_smile.xml')\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.read(\"./PersonalFace/trainedmodel/trainner.yml\")\n",
    "\n",
    "    labels = {}\n",
    "    with open('./PersonalFace/trainedmodel/label.pickle', 'rb') as f:\n",
    "        og_labels = pickle.load(f)\n",
    "        labels = {v:k for k, v in og_labels.items()}\n",
    "\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    i = 0\n",
    "    stroke = 2\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            #print(x, y, w, h)\n",
    "            img_item = str(i)+\".png\"\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "            id_, conf = recognizer.predict(roi_gray)\n",
    "            #print(labels[id_])\n",
    "            cv2.putText(frame, labels[id_], (x, y), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), stroke)\n",
    "\n",
    "            color= (0, 0, 255) #BGR\n",
    "            stroke = 2\n",
    "            width = x + w\n",
    "            height = y + h\n",
    "            cv2.rectangle(frame, (x - 10, y), (width + 10, height + 20), color, stroke)\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "            #for (ex, ey, ew, eh) in eyes:\n",
    "            #   cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0))\n",
    "            # smile = smile_cascade.detectMultiScale(roi_gray)\n",
    "            # for (sx, sy, sw, sh) in smile:\n",
    "            #     cv2.rectangle(roi_color, (sx, sy), (sx+sw, sy+sh), (255, 0, 0))\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def detectEmotion():\n",
    "    num_classes = 6\n",
    "    img_rows, img_cols = 48, 48\n",
    "    batch_size = 16\n",
    "\n",
    "    train_data_dir = './images/train'\n",
    "    validation_data_dir = './images/validation'\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        color_mode='grayscale',\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False    \n",
    "    )\n",
    "\n",
    "    class_labels = validation_generator.class_indices\n",
    "    class_labels = {v: k for k, v in class_labels.items()}\n",
    "    classes = list(class_labels.values())\n",
    "    print(class_labels)\n",
    "    \n",
    "    classifier = load_model('./TrainedModel/4(67)/Emotion_detector.h5')    \n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.read('./PersonalFace/trainedmodel/trainner.yml')\n",
    "\n",
    "    labels = {}\n",
    "    with open('./PersonalFace/trainedmodel/label.pickle', 'rb') as f:\n",
    "        og_label = pickle.load(f)\n",
    "        labels = {v: k for k, v in og_label.items()}\n",
    "    # print(labels)\n",
    "\n",
    "    def face_detector(img, gray):\n",
    "        #gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        if faces == ():\n",
    "            return (0, 0, 0, 0), np.zeros((48, 48), np.uint8), img\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(img, (x-30, y-30), (x+w+20, y+h+20), (255, 0, 0), 2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "        try:\n",
    "            roi_gray = cv2.resize(roi_gray, (48, 48), interpolation=cv2.INTER_AREA)\n",
    "        except:\n",
    "            return (x, y, w, h), np.zeros((48, 48), np.uint8), img\n",
    "\n",
    "        return (x, y, w, h), roi_gray, img\n",
    "\n",
    "    cap = cv2.VideoCapture(1)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rect, face, image = face_detector(frame, gray)\n",
    "        if np.sum([face]) != 0.0:\n",
    "            roi = face.astype(\"float\") / 255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi, axis=0)\n",
    "            preds = classifier.predict(roi)[0]\n",
    "\n",
    "            roi_gray = gray[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]]\n",
    "            id_, conf = recognizer.predict(roi_gray)\n",
    "            \n",
    "            print(max(preds))\n",
    "            label = labels[id_]+\" is \"+class_labels[preds.argmax()] + \":\" + str(round(max(preds) * 100, 2))\n",
    "            label_position = (rect[0] + int((rect[1])), rect[2] + 25)\n",
    "            cv2.putText(image, label, label_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 1)\n",
    "\n",
    "        else:\n",
    "            cv2.putText(image, \"No Face found\", (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 1)\n",
    "\n",
    "        cv2.imshow('Emotion Detection', image)\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "root.title(\"Personal Face Recognition and Emotion-Recognition\")\n",
    "root.geometry('500x570')\n",
    "tf = Frame(root, width = 480, height = 50, bd = 2, relief = \"ridge\")\n",
    "tf.place(x = 10, y = 10)\n",
    "title = Label(tf,font = (\"Helvetica\",30),fg = \"blue\",text = \"       Emotion Detection      \")\n",
    "title.pack() \n",
    "\n",
    "button1 = Button(root, command = faceRecord, padx = 5, pady = 5, relief = RIDGE, width = 33, background = 'cyan',font  = (\"georgia\",15), text = \"Open webcam for personal face detection\", bd = 5)\n",
    "button1.place(x = 20, y = 80)\n",
    "\n",
    "button2 = Button(root, command = trainFace, padx = 5, pady = 5, relief = RIDGE, width = 33, background = 'cyan',font  = (\"georgia\",15), text = \"Train your face\", bd = 5)\n",
    "button2.place(x = 20, y = 160)\n",
    "\n",
    "button3 = Button(root, command = personalFace, padx = 5, pady = 5, relief = RIDGE, width = 33, background = 'cyan',font  = (\"georgia\",15), text = \"Your Personal Face\", bd = 5)\n",
    "button3.place(x = 20, y = 240)\n",
    "\n",
    "button4 = Button(root, command = detectEmotion, padx = 5, pady = 5, relief = RIDGE, width = 33, background = 'cyan',font  = (\"georgia\",15), text = \"Emotion with your face\", bd = 5)\n",
    "button4.place(x = 20, y = 320)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
